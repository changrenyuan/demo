<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Companion TTS & Sprite</title>
    <!-- Load Tailwind CSS CDN for modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* [UI æ ·å¼ä¿æŒä¸å˜] */
        body { font-family: 'Inter', sans-serif; background-color: #f7f9fc; }
        .companion-container { width: 100%; max-width: 320px; box-shadow: 0 10px 30px -5px rgba(0, 0, 0, 0.15); border-radius: 2rem; background-color: #ffffff; overflow: hidden; transition: all 0.3s ease; }
        canvas { display: block; width: 100%; height: 280px; background-color: #e6f7ff; border-top-left-radius: 2rem; border-top-right-radius: 2rem; }
        #chat-log { max-height: 200px; overflow-y: auto; border-top: 2px solid #e0f0ff; padding: 1rem; background-color: #ffffff; }
        .chat-bubble { max-width: 85%; padding: 0.65rem 0.9rem; border-radius: 1.25rem; margin-bottom: 0.75rem; font-size: 0.95rem; line-height: 1.4; word-wrap: break-word; animation: fadeIn 0.3s ease-out; }
        @keyframes fadeIn { from { opacity: 0; transform: translateY(5px); } to { opacity: 1; transform: translateY(0); } }
        .interaction-area input, .interaction-area button { height: 48px; font-size: 1.1rem; }
    </style>
    
    <!-- Firebase SDKs (ç¯å¢ƒè¦æ±‚) -->
    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        // å¯¼å…¥æ‰€æœ‰éœ€è¦çš„ Firebase æ¨¡å—ï¼Œä½†åªåœ¨ä¸‹æ–¹çš„ JS å—ä¸­ä½¿ç”¨å®ƒä»¬
        import { getAuth, signInAnonymously, signInWithCustomToken } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, setLogLevel } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        // å°†é…ç½®å…¨å±€åŒ–ï¼Œä¾›åç»­æ¨¡å—è„šæœ¬ä½¿ç”¨
        const firebaseConfig = JSON.parse(typeof __firebase_config !== 'undefined' ? __firebase_config : '{}');
        window.firebaseConfig = firebaseConfig;
    </script>
</head>
<body class="p-6 min-h-screen flex items-center justify-center">

    <div class="companion-container flex flex-col items-center">
        <!-- è§’è‰²æ˜¾ç¤ºåŒºåŸŸ -->
        <canvas id="companionCanvas" width="320" height="280"></canvas>

        <!-- èŠå¤©æ—¥å¿—åŒºåŸŸ -->
        <div id="chat-log" class="w-full text-sm">
            <div class="chat-bubble bg-gray-200 text-gray-800 mr-auto">
                <span class="font-semibold text-blue-600">ä¼´ä¾£AI (Beluga)</span>: è¯­éŸ³å’Œå½¢è±¡å·²å°±ç»ªã€‚è¯·å¼€å§‹å¯¹è¯ï¼
            </div>
        </div>
        
        <!-- è¾“å…¥åŒºåŸŸ -->
        <div class="interaction-area w-full p-4 border-t border-gray-100 flex space-x-2">
            <input type="text" id="userInput" placeholder="è¾“å…¥æ¶ˆæ¯..." 
                   class="flex-grow p-3 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 transition"
                   onkeydown="if(event.key === 'Enter') document.getElementById('sendButton').click()">
            <button id="sendButton" 
                    class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-5 rounded-xl shadow-lg transition duration-150 ease-in-out"
                    disabled>
                å‘é€
            </button>
        </div>
        <p id="status-message" class="text-xs text-red-500 mb-2"></p>
    </div>

    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously, signInWithCustomToken } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, setLogLevel } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        const canvas = document.getElementById('companionCanvas');
        const ctx = canvas.getContext('2d');
        const chatLog = document.getElementById('chat-log');
        const userInput = document.getElementById('userInput');
        const sendButton = document.getElementById('sendButton');
        const statusMessage = document.getElementById('status-message');

        // Core state variables
        let currentAction = 'idle'; 
        let currentEmotion = 'neutral'; 
        let talkingPhase = 0; 

        // --- Sprite Sheet Configuration ---
        const SPRITE_FRAME_SIZE = 128; 
        // ğŸš¨ğŸš¨ è¯·æ›¿æ¢ä¸ºæ‚¨å®é™…çš„ç²¾çµå›¾ URL ğŸš¨ğŸš¨
        const SPRITE_URL = 'sprite_sheet.png'; // å ä½å›¾ï¼š6 å¸§ x 128pxï¼›
        const characterSprite = new Image();
        let isSpriteLoaded = false;
        
        const EMOTION_MAP = {
            'neutral': 0, 'happy': 1, 'surprised': 2, 'sad': 3,
            'excited': 4, 'thinking': 5,
        };

        characterSprite.onload = () => {
            isSpriteLoaded = true;
            sendButton.disabled = false;
            statusMessage.textContent = "";
            appendMessage('ai', "ç²¾çµå›¾åŠ è½½å®Œæˆï¼è¯·å¼€å§‹å¯¹è¯å§ã€‚", true);
        };

        characterSprite.onerror = () => {
            statusMessage.textContent = "è­¦å‘Šï¼šç²¾çµå›¾åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥ SPRITE_URL æ˜¯å¦æ­£ç¡®ï¼Œå½“å‰ä½¿ç”¨çš„æ˜¯å ä½å›¾ã€‚";
        };

        characterSprite.src = SPRITE_URL;
        
        // --- Firebase Initialization (Required for Canvas Environment) ---
        async function initFirebase() {
            try {
                // ä¿®æ­£: æ£€æŸ¥ window.firebaseConfig æ˜¯å¦æœ‰æ•ˆï¼Œé¿å…å› é…ç½®ç¼ºå¤±å¯¼è‡´çš„è‡´å‘½é”™è¯¯
                if (Object.keys(window.firebaseConfig).length === 0) {
                    console.warn("[Firebase] Config missing. Running without persistent storage.");
                    return; 
                }

                const app = initializeApp(window.firebaseConfig);
                const auth = getAuth(app);
                // const db = getFirestore(app); // Note: We are not using Firestore, but initialization is fine.
                setLogLevel('error'); 

                const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;
                if (initialAuthToken) {
                    await signInWithCustomToken(auth, initialAuthToken);
                } else {
                    await signInAnonymously(auth);
                }
                console.log("[Firebase] Auth successful.");

            } catch (error) {
                // æ•è· API Key æ— æ•ˆæˆ–åˆå§‹åŒ–å¤±è´¥çš„é”™è¯¯ï¼Œå¹¶è®°å½•
                console.error("[Firebase Error] Initialization failed (This may be due to missing/invalid API Key in config):", error.message);
            }
        }

        // --- Character Drawing Logic (Based on Sprite Sheet) ---

        function drawCharacter(action, emotion, timestamp) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (!isSpriteLoaded) return;

            const centerX = canvas.width / 2;
            const centerY = canvas.height / 2;
            const size = 180; 
            
            const drawingEmotion = action === 'thinking' ? 'thinking' : emotion;
            const frameIndex = EMOTION_MAP[drawingEmotion] || 0; 
            
            const sourceX = frameIndex * SPRITE_FRAME_SIZE;
            const sourceY = 0;
            
            let offsetY = 0; 
            if (emotion === 'excited' && action !== 'thinking') {
                offsetY = Math.sin(timestamp / 80) * 3; 
            }

            const destX = centerX - size / 2;
            const destY = centerY - size / 2 + offsetY;

            ctx.drawImage(
                characterSprite, 
                sourceX, 
                sourceY, 
                SPRITE_FRAME_SIZE, 
                SPRITE_FRAME_SIZE, 
                destX, 
                destY, 
                size, 
                size
            );
        }

        // --- Animation Loop ---
        function animate(timestamp) {
            requestAnimationFrame(animate);

            if (currentAction === 'talking') {
                talkingPhase += 0.3;
            } else {
                talkingPhase = 0;
            }
            
            drawCharacter(currentAction, currentEmotion, timestamp);
        }

        // --- Semantic Emotion Analysis (Unchanged) ---
        function getSemanticEmotionFromText(text) {
            const lowerText = text.toLowerCase();
            if (lowerText.includes('å¤ªæ£’äº†') || lowerText.includes('å¥½æäº†') || lowerText.includes('æœ€æ£’') || lowerText.includes('éå¸¸å¼€å¿ƒ') || lowerText.includes('å“‡')) {
                return 'excited';
            }
            if (lowerText.includes('å¯¹ä¸èµ·') || lowerText.includes('å¾ˆéš¾è¿‡') || lowerText.includes('æŠ±æ­‰') || lowerText.includes('ä¼¤å¿ƒ') || lowerText.includes('å¤±è´¥')) {
                return 'sad';
            }
            if (lowerText.includes('å—') || lowerText.includes('å‘¢') || lowerText.includes('å‘€') || lowerText.includes('æ˜¯ä»€ä¹ˆ') || lowerText.includes('ä¸çŸ¥é“')) {
                return 'surprised';
            }
            if (lowerText.includes('ä½ å¥½') || lowerText.includes('æ¬¢è¿') || lowerText.includes('å¾ˆé«˜å…´') || lowerText.includes('å¯ä»¥å‘€') || lowerText.includes('é¼“åŠ±') || lowerText.includes('å¼€å¿ƒ')) {
                return 'happy';
            }
            return 'neutral';
        }

        // --- TTS Utility Functions (Unchanged) ---

        /**
         * Decodes a Base64 string to an ArrayBuffer.
         */
        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        /**
         * Wraps 16-bit signed PCM data into a standard WAV Blob.
         */
        function pcmToWav(pcm16, sampleRate) {
            const numChannels = 1;
            const bytesPerSample = 2; // 16-bit PCM
            const dataLength = pcm16.length * bytesPerSample;
            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);
            let offset = 0;

            // Writes a string to the DataView
            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset++, str.charCodeAt(i));
                }
            }

            // RIFF chunk descriptor
            writeString('RIFF'); 
            view.setUint32(offset, 36 + dataLength, true); 
            offset += 4;
            writeString('WAVE'); 
            
            // FMT sub-chunk
            writeString('fmt '); 
            view.setUint32(offset, 16, true); 
            offset += 4;
            view.setUint16(offset, 1, true); // Audio Format (1 for PCM)
            offset += 2;
            view.setUint16(offset, numChannels, true); 
            offset += 2;
            view.setUint32(offset, sampleRate, true); 
            offset += 4;
            view.setUint32(offset, sampleRate * numChannels * bytesPerSample, true); 
            offset += 4;
            view.setUint16(offset, numChannels * bytesPerSample, true); 
            offset += 2;
            view.setUint16(offset, bytesPerSample * 8, true); // Bits Per Sample (16)
            offset += 2;

            // DATA sub-chunk
            writeString('data'); 
            view.setUint32(offset, dataLength, true); 
            offset += 4;

            // Write PCM data
            for (let i = 0; i < pcm16.length; i++) {
                view.setInt16(offset, pcm16[i], true);
                offset += 2;
            }

            return new Blob([view], { type: 'audio/wav' });
        }


        // --- Gemini API & Dialogue Logic ---

        // ***************************************************************
        // ** è¯·æ³¨æ„: å¦‚æœæ‚¨åœ¨æœ¬åœ°è¿è¡Œæ­¤æ–‡ä»¶ï¼Œè¯·åœ¨æ­¤å¤„å¡«å…¥æ‚¨çš„ Google API å¯†é’¥ **
        // ***************************************************************
        const LOCAL_API_KEY = "AIzaSyAeM0SBO7GlbPmLGrCYq7NqD6fy1SSZpEw"; // <--- è¯·å°†æ‚¨çš„å¯†é’¥ç²˜è´´åˆ°è¿™å¯¹å¼•å·ä¸­é—´

        // Use Canvas injected Key if present, otherwise use local Key
        // ä¿®æ­£: è¿™é‡Œçš„ API_KEY ä»…ç”¨äº LLM/TTS è°ƒç”¨ã€‚
        const API_KEY = typeof __initial_auth_token !== 'undefined' ? "" : LOCAL_API_KEY; 

        if (!API_KEY && typeof __initial_auth_token === 'undefined') {
             statusMessage.textContent = "è­¦å‘Šï¼šAPI Key æœªè®¾ç½®ã€‚è¯·åœ¨ä»£ç ä¸­å¡«å…¥æ‚¨çš„å¯†é’¥ä»¥è¿›è¡Œæœ¬åœ°æµ‹è¯•ã€‚";
        }
        
        const LLM_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${API_KEY}`;
        const TTS_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${API_KEY}`;
        const MAX_RETRIES = 5;

        // General Fetch with Retry Logic (Unchanged)
        async function fetchWithRetry(url, payload, attempt = 0) {
            if (!API_KEY) throw new Error("API Key is missing for local execution or Canvas environment.");
            
            const delay = Math.pow(2, attempt) * 1000;
            if (attempt > 0) await new Promise(resolve => setTimeout(resolve, delay));

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (response.status === 429 && attempt < MAX_RETRIES) {
                    return fetchWithRetry(url, payload, attempt + 1);
                }

                if (!response.ok) {
                    const errorBody = await response.json();
                    throw new Error(`API error: ${response.status} - ${errorBody.error?.message || response.statusText}`);
                }

                return response.json();

            } catch (error) {
                if (attempt < MAX_RETRIES && error.message.includes('Failed to fetch')) {
                    return fetchWithRetry(url, payload, attempt + 1);
                }
                throw new Error(`Failed to fetch from API: ${error.message}`);
            }
        }

        /**
         * Calls the TTS API and plays the audio. (Unchanged)
         */
        function playTextToSpeech(text) {
            return new Promise(async (resolve, reject) => {
                const payload = {
                    contents: [{
                        parts: [{ text: text }]
                    }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            // Using Kore voice for a clear, firm tone, and explicitly setting language to Chinese
                            voiceConfig: { prebuiltVoiceConfig: { voiceName: "Kore" } },
                            languageCode: "zh-CN"
                        }
                    },
                    model: "gemini-2.5-flash-preview-tts"
                };

                try {
                    const result = await fetchWithRetry(TTS_API_URL, payload);
                    const part = result?.candidates?.[0]?.content?.parts?.[0];
                    const audioData = part?.inlineData?.data;
                    const mimeType = part?.inlineData?.mimeType;

                    if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                        const rateMatch = mimeType.match(/rate=(\d+)/);
                        const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000; 
                        
                        // Convert Base64 PCM data to WAV Blob
                        const pcmData = base64ToArrayBuffer(audioData);
                        const pcm16 = new Int16Array(pcmData);
                        const wavBlob = pcmToWav(pcm16, sampleRate);
                        const audioUrl = URL.createObjectURL(wavBlob);
                        
                        // Play the audio
                        const audio = new Audio(audioUrl);
                        audio.play();

                        audio.onended = () => {
                            URL.revokeObjectURL(audioUrl); // Release memory after playback
                            resolve();
                        };
                        audio.onerror = (e) => {
                            URL.revokeObjectURL(audioUrl); 
                            console.error("Audio playback error (Browser):", e);
                            reject(new Error("éŸ³é¢‘æ’­æ”¾å¤±è´¥ (è¯·æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°)"));
                        };

                    } else {
                        console.error("TTS response missing audio data or invalid format:", result);
                        reject(new Error("TTS API æœªè¿”å›æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®ã€‚"));
                    }
                } catch (error) {
                    reject(error);
                }
            });
        }


        // LLM Text Generation Logic (Using LLM_API_URL) (Unchanged)
        async function askGemini(userQuery) {
            const systemPrompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸ºå„¿ç«¥å’Œé’å°‘å¹´è®¾è®¡çš„å¯çˆ±AIä¼´ä¾£ï¼Œåå­—å«'å°ç™½é²¸' (Beluga)ã€‚è¯·ç”¨ç§¯æã€å‹å–„å’Œé¼“åŠ±çš„è¯­æ°”è¿›è¡Œå›å¤ã€‚ä½ çš„å›ç­”åº”è¯¥ç®€çŸ­ã€æœ‰è¶£ï¼Œä¸”é€‚åˆå¹´é¾„è¾ƒå°çš„ç”¨æˆ·ã€‚**è¯·åœ¨å›ç­”ä¸­è‡ªç„¶åœ°ä½¿ç”¨èƒ½è¡¨è¾¾æƒ…æ„Ÿçš„è¯è¯­**ï¼Œå¦‚ 'å¤ªæ£’äº†', 'ä¸ºä»€ä¹ˆå‘¢', 'æˆ‘å¾ˆæŠ±æ­‰' ç­‰ã€‚å›å¤è¯·ä½¿ç”¨ä¸­æ–‡ã€‚";
            
            const payload = {
                contents: [{ parts: [{ text: userQuery }] }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };
            
            try {
                const result = await fetchWithRetry(LLM_API_URL, payload);
                const candidate = result.candidates?.[0];

                if (candidate && candidate.content?.parts?.[0]?.text) {
                    return candidate.content.parts[0].text;
                } else {
                    return "å¯¹ä¸èµ·ï¼Œæˆ‘æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·å†è¯•ä¸€æ¬¡ã€‚";
                }
            } catch (error) {
                console.error("Gemini LLM API Error:", error);
                statusMessage.textContent = `æ–‡æœ¬ç”Ÿæˆ API é”™è¯¯: ${error.message}`;
                return "è¿æ¥ä¼´ä¾£AIçš„å¤§è„‘å¤±è´¥äº†ã€‚å¥½åƒç½‘ç»œæœ‰ç‚¹å°é—®é¢˜å‘¢ã€‚";
            }
        }


        async function handleUserInteraction() {
            const message = userInput.value.trim();
            if (!message || !isSpriteLoaded) return;
            
            // ä¿®æ­£: å§‹ç»ˆä½¿ç”¨ API_KEY å˜é‡è¿›è¡Œæ£€æŸ¥
            if (!API_KEY) {
                statusMessage.textContent = "è¯·å…ˆåœ¨ä»£ç ä¸­é…ç½®æ‚¨çš„ API Keyï¼";
                return;
            }

            appendMessage('user', message);
            userInput.value = '';
            
            // 1. è§’è‰²è¿›å…¥ 'thinking' åŠ¨ä½œçŠ¶æ€
            sendButton.disabled = true;
            userInput.disabled = true;
            currentAction = 'thinking';
            statusMessage.textContent = "AIæ­£åœ¨æ€è€ƒä¸­...";
            
            // 2. è°ƒç”¨ LLM è·å–æ–‡æœ¬
            const aiResponseText = await askGemini(message);

            // 3. è¯­ä¹‰åˆ†æï¼Œç¡®å®šæƒ…æ„ŸçŠ¶æ€
            const semanticEmotion = getSemanticEmotionFromText(aiResponseText);
            currentEmotion = semanticEmotion; 
            
            // 4. æ˜¾ç¤ºæ–‡æœ¬å›å¤
            appendMessage('ai', aiResponseText);
            
            // 5. è§’è‰²è¿›å…¥ 'talking' åŠ¨ä½œçŠ¶æ€
            currentAction = 'talking';

            // 6. è°ƒç”¨ TTS API å¹¶ç­‰å¾…æ’­æ”¾å®Œæˆ
            try {
                statusMessage.textContent = "AIæ­£åœ¨è¯´è¯ (è¯·ç¡®ä¿å£°éŸ³å¼€å¯)...";
                await playTextToSpeech(aiResponseText);
                statusMessage.textContent = "";
            } catch (e) {
                // å¦‚æœ TTS å¤±è´¥ï¼Œä»ç„¶æ¢å¤è¾“å…¥
                statusMessage.textContent = `è¯­éŸ³æ’­æ”¾å¤±è´¥: ${e.message}`;
            }
            
            // 7. æ’­æ”¾å®Œæ¯•ï¼ŒåŠ¨ä½œå›åˆ° 'idle'
            currentAction = 'idle';
            
            // 8. ä¿æŒæƒ…æ„ŸçŠ¶æ€ä¸€å°æ®µæ—¶é—´ï¼Œå†å›åˆ°ä¸­æ€§
            setTimeout(() => {
                currentEmotion = 'neutral';
            }, 2000); 

            // 9. é‡æ–°å¯ç”¨è¾“å…¥
            sendButton.disabled = false;
            userInput.disabled = false;
            userInput.focus();
        }

        function appendMessage(sender, message) {
            const bubble = document.createElement('div');
            bubble.classList.add('chat-bubble', 'flex', 'items-start');

            if (sender === 'user') {
                bubble.classList.add('bg-blue-500', 'text-white', 'ml-auto');
                bubble.textContent = message;
            } else {
                bubble.classList.add('bg-gray-200', 'text-gray-800', 'mr-auto');
                
                const textContainer = document.createElement('div');
                textContainer.innerHTML = `<span class="font-semibold text-blue-600">ä¼´ä¾£AI (Beluga)</span>: ${message}`;
                
                bubble.innerHTML = textContainer.innerHTML;
            }
            chatLog.appendChild(bubble);
            chatLog.scrollTop = chatLog.scrollHeight;
        }

        // --- Event Binding and Launch ---
        sendButton.addEventListener('click', handleUserInteraction);

        window.onload = function () {
            initFirebase();
            animate(0);
        };

    </script>
</body>
</html>